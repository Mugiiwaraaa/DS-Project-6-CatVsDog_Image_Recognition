{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006bc959",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c dogs-vs-cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5abb0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting compressed files\n",
    "from zipfile import ZipFile\n",
    "dataset = 'dogs-vs-cats.zip'\n",
    "with ZipFile(dataset,'r') as zip:\n",
    "    zip.extractall()\n",
    "    print(\"The Dataset is Extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548fcb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting train folder cause this is the only one we want\n",
    "dataset = 'train.zip'\n",
    "with ZipFile(dataset,'r') as zip:\n",
    "    zip.extractall()\n",
    "    print(\"The Dataset is Extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a75ca702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #counting number of files in the train folder\n",
    "import os \n",
    "paths,dirs,files=next(os.walk('train'))\n",
    "file_count=len(files)\n",
    "print(f\"{file_count} Number of images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495831e",
   "metadata": {},
   "source": [
    "## Prepocessing the images for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb14173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dependancies \n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126a10e1",
   "metadata": {},
   "source": [
    "### displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3977e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #displaying the images of dog\n",
    "img = mpimg.imread('train/dog.8928.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20edcd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #displaying the images of cat\n",
    "img2 = mpimg.imread('train/cat.4928.jpg')\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea26c5",
   "metadata": {},
   "source": [
    "##### These images are not in same shape and since our model requires a specific shape. we manipulate and resize all images in the required size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af272a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=os.listdir('train')\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1c5df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_count=0\n",
    "cat_count=0\n",
    "\n",
    "for img_file in file_names:\n",
    "    name=img_file[0:3]\n",
    "    if name == 'dog':\n",
    "        dog_count+=1\n",
    "    elif name == 'cat':\n",
    "        cat_count+=1\n",
    "print(\"Number of dogs =\" , dog_count)\n",
    "print(\"Number of cats =\" , cat_count)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3672935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('dogs')\n",
    "os.mkdir('cats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "406c26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dogs and cats in different folders to make it easier for an even split of datasets\n",
    "dog_folder = 'dogs/'\n",
    "cat_folder = 'cats/'\n",
    "original_folder='train/'\n",
    "\n",
    "for i in range(25000): #25000 because i know there are 25000 images in the folder\n",
    "    filename=os.listdir('train')[i]\n",
    "    img_path=original_folder+filename\n",
    "    img = Image.open(img_path)\n",
    "    name=filename[0:3]\n",
    "    cat_img_path = cat_folder+filename\n",
    "    dog_img_path = dog_folder+filename\n",
    "    img = Image.open(img_path)\n",
    "    if name=='dog':\n",
    "        img.save(dog_img_path)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b79eb8",
   "metadata": {},
   "source": [
    "#### Resizing all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9e3430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new directory for resized images\n",
    "\n",
    "os.mkdir('resizedimages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2253ffd",
   "metadata": {},
   "source": [
    "#### WE need only 2000 images of cats and 2000 images of dogs since we are using a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b368c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing cat images\n",
    "original_folder='cats/'\n",
    "resized_folder='resizedimages/'\n",
    "\n",
    "for i in range(1000):\n",
    "    filename=os.listdir('cats')[i]\n",
    "    img_path=original_folder+filename\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((224,224)) #we need specific size for our mobilenet pretrained model\n",
    "    img=img.convert('RGB')\n",
    "    \n",
    "    new_img_path = resized_folder+filename\n",
    "    img.save(new_img_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f177062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing dog images\n",
    "original_folder='dogs/'\n",
    "resized_folder='resizedimages/'\n",
    "\n",
    "for i in range(1000):\n",
    "    filename=os.listdir('dogs')[i]\n",
    "    img_path=original_folder+filename\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((224,224)) #we need specific size for our mobilenet pretrained model\n",
    "    img=img.convert('RGB')\n",
    "    \n",
    "    new_img_path = resized_folder+filename\n",
    "    img.save(new_img_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "320a526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #displaying resized images of dog\n",
    "img = mpimg.imread('resizedimages/dog.307.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c31038b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #displaying resized images of cat\n",
    "img = mpimg.imread('resizedimages/cat.1060.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9bcf04",
   "metadata": {},
   "source": [
    "## Creating labels for resized images of dogs and cats\n",
    "### Cats --> 1\n",
    "### Dogs --> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ceee238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filename=os.listdir('resizedimages/')\n",
    "labels=[]\n",
    "for i in range(2000):\n",
    "    file_name=filename[i]\n",
    "    label=file_name[0:3]\n",
    "    \n",
    "    if label=='cat':\n",
    "        labels.append(1)\n",
    "    elif label=='dog':\n",
    "        labels.append(0)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81f3d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "values,counts =np.unique(labels,return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "affa1244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "203d9380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1000, 1000], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39f465b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all resized images to NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1848c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb3f92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagedir='resizedimages/'\n",
    "image_extension= ['png','jpg']\n",
    "\n",
    "files=[]\n",
    "[files.extend(glob.glob(imagedir + '*.' + e)) for e in image_extension]\n",
    "\n",
    "dog_cat_images=np.asarray([cv2.imread(file) for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5a9c62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 224, 224, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_cat_images.shape , type(dog_cat_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd5488ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dog_cat_images\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f559e",
   "metadata": {},
   "source": [
    "## splitting the data into train-test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c64b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train , features_test , labels_train , labels_test = train_test_split(features,labels,test_size=0.2,random_state=42,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9020ca37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600, 224, 224, 3), (400, 224, 224, 3))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape , features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4375062b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600,), (400,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape , labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e3b58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 1600 training datasets and 400 test datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe8b7e",
   "metadata": {},
   "source": [
    "### Feature scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3452d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing all values by 255 because the that is my maximum intensity of colors\n",
    "scaled_features_train = features_train/255\n",
    "scaled_features_test = features_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c9ceef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.35294118, 0.50588235, 0.63137255],\n",
       "         [0.36862745, 0.52156863, 0.64705882],\n",
       "         [0.38039216, 0.53333333, 0.65882353],\n",
       "         ...,\n",
       "         [0.23921569, 0.34117647, 0.40784314],\n",
       "         [0.23921569, 0.34117647, 0.40784314],\n",
       "         [0.22745098, 0.32941176, 0.39607843]],\n",
       "\n",
       "        [[0.37647059, 0.52941176, 0.65490196],\n",
       "         [0.39215686, 0.54509804, 0.67058824],\n",
       "         [0.4       , 0.55294118, 0.67843137],\n",
       "         ...,\n",
       "         [0.22352941, 0.3254902 , 0.39215686],\n",
       "         [0.21568627, 0.31764706, 0.38431373],\n",
       "         [0.2       , 0.30196078, 0.36862745]],\n",
       "\n",
       "        [[0.38431373, 0.5372549 , 0.6627451 ],\n",
       "         [0.4       , 0.55294118, 0.67843137],\n",
       "         [0.41176471, 0.56470588, 0.69019608],\n",
       "         ...,\n",
       "         [0.21568627, 0.30980392, 0.38039216],\n",
       "         [0.20392157, 0.29803922, 0.36862745],\n",
       "         [0.18431373, 0.27843137, 0.34901961]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.14117647, 0.24705882, 0.38039216],\n",
       "         [0.15294118, 0.25882353, 0.39215686],\n",
       "         [0.18431373, 0.29411765, 0.42745098],\n",
       "         ...,\n",
       "         [0.23921569, 0.39215686, 0.51764706],\n",
       "         [0.23529412, 0.38823529, 0.51372549],\n",
       "         [0.21176471, 0.36470588, 0.49019608]],\n",
       "\n",
       "        [[0.14901961, 0.25490196, 0.38823529],\n",
       "         [0.15686275, 0.2627451 , 0.39607843],\n",
       "         [0.18039216, 0.29019608, 0.42352941],\n",
       "         ...,\n",
       "         [0.24705882, 0.4       , 0.5254902 ],\n",
       "         [0.23529412, 0.38823529, 0.51372549],\n",
       "         [0.2       , 0.35294118, 0.47843137]],\n",
       "\n",
       "        [[0.16078431, 0.26666667, 0.4       ],\n",
       "         [0.16470588, 0.27058824, 0.40392157],\n",
       "         [0.18431373, 0.29411765, 0.42745098],\n",
       "         ...,\n",
       "         [0.24705882, 0.4       , 0.5254902 ],\n",
       "         [0.22745098, 0.38039216, 0.50588235],\n",
       "         [0.18431373, 0.3372549 , 0.4627451 ]]],\n",
       "\n",
       "\n",
       "       [[[0.60392157, 0.69019608, 0.7372549 ],\n",
       "         [0.61176471, 0.69803922, 0.74509804],\n",
       "         [0.60784314, 0.70588235, 0.74509804],\n",
       "         ...,\n",
       "         [0.42352941, 0.52156863, 0.5372549 ],\n",
       "         [0.43137255, 0.52941176, 0.54509804],\n",
       "         [0.43529412, 0.53333333, 0.54901961]],\n",
       "\n",
       "        [[0.57647059, 0.6627451 , 0.70980392],\n",
       "         [0.58431373, 0.67058824, 0.71372549],\n",
       "         [0.58039216, 0.67843137, 0.71764706],\n",
       "         ...,\n",
       "         [0.42745098, 0.5254902 , 0.54117647],\n",
       "         [0.43137255, 0.52941176, 0.54509804],\n",
       "         [0.43529412, 0.53333333, 0.54901961]],\n",
       "\n",
       "        [[0.54117647, 0.62745098, 0.67058824],\n",
       "         [0.54509804, 0.63137255, 0.6745098 ],\n",
       "         [0.55294118, 0.63921569, 0.68235294],\n",
       "         ...,\n",
       "         [0.43137255, 0.52941176, 0.54509804],\n",
       "         [0.43529412, 0.53333333, 0.54901961],\n",
       "         [0.43921569, 0.5372549 , 0.55294118]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.76862745, 0.68235294, 0.63921569],\n",
       "         [0.78039216, 0.69411765, 0.65098039],\n",
       "         [0.78431373, 0.70588235, 0.6627451 ],\n",
       "         ...,\n",
       "         [0.5372549 , 0.52941176, 0.49803922],\n",
       "         [0.52941176, 0.53333333, 0.49803922],\n",
       "         [0.52941176, 0.53333333, 0.49803922]],\n",
       "\n",
       "        [[0.76862745, 0.68235294, 0.63921569],\n",
       "         [0.78039216, 0.69411765, 0.65098039],\n",
       "         [0.78431373, 0.70588235, 0.6627451 ],\n",
       "         ...,\n",
       "         [0.52941176, 0.53333333, 0.49803922],\n",
       "         [0.5254902 , 0.52941176, 0.49411765],\n",
       "         [0.52156863, 0.5254902 , 0.49019608]],\n",
       "\n",
       "        [[0.76862745, 0.68235294, 0.63921569],\n",
       "         [0.78039216, 0.69411765, 0.65098039],\n",
       "         [0.78431373, 0.70588235, 0.6627451 ],\n",
       "         ...,\n",
       "         [0.54509804, 0.54901961, 0.51372549],\n",
       "         [0.53333333, 0.5372549 , 0.50196078],\n",
       "         [0.5254902 , 0.52941176, 0.49411765]]],\n",
       "\n",
       "\n",
       "       [[[0.38039216, 0.50980392, 0.58431373],\n",
       "         [0.34117647, 0.47058824, 0.54509804],\n",
       "         [0.50980392, 0.63921569, 0.71372549],\n",
       "         ...,\n",
       "         [0.3372549 , 0.44313725, 0.54901961],\n",
       "         [0.28235294, 0.39607843, 0.50196078],\n",
       "         [0.19215686, 0.30588235, 0.41176471]],\n",
       "\n",
       "        [[0.46666667, 0.59607843, 0.67058824],\n",
       "         [0.41176471, 0.54117647, 0.61568627],\n",
       "         [0.54509804, 0.6745098 , 0.74901961],\n",
       "         ...,\n",
       "         [0.34509804, 0.45098039, 0.55686275],\n",
       "         [0.30588235, 0.41960784, 0.5254902 ],\n",
       "         [0.24705882, 0.36078431, 0.46666667]],\n",
       "\n",
       "        [[0.55294118, 0.6745098 , 0.75686275],\n",
       "         [0.47058824, 0.59215686, 0.6745098 ],\n",
       "         [0.54901961, 0.67058824, 0.75294118],\n",
       "         ...,\n",
       "         [0.38431373, 0.49019608, 0.59215686],\n",
       "         [0.36470588, 0.47058824, 0.57647059],\n",
       "         [0.35294118, 0.45882353, 0.56470588]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.24705882, 0.32156863, 0.37254902],\n",
       "         [0.22352941, 0.29803922, 0.34901961],\n",
       "         [0.40784314, 0.47058824, 0.53333333],\n",
       "         ...,\n",
       "         [0.74901961, 0.75294118, 0.80784314],\n",
       "         [0.74509804, 0.74509804, 0.79215686],\n",
       "         [0.7372549 , 0.7372549 , 0.78431373]],\n",
       "\n",
       "        [[0.19607843, 0.2745098 , 0.31764706],\n",
       "         [0.21568627, 0.29019608, 0.34117647],\n",
       "         [0.33333333, 0.4       , 0.45098039],\n",
       "         ...,\n",
       "         [0.74901961, 0.75294118, 0.80784314],\n",
       "         [0.7372549 , 0.7372549 , 0.78431373],\n",
       "         [0.7254902 , 0.7254902 , 0.77254902]],\n",
       "\n",
       "        [[0.28627451, 0.36470588, 0.40784314],\n",
       "         [0.27058824, 0.34901961, 0.39215686],\n",
       "         [0.19607843, 0.2627451 , 0.31372549],\n",
       "         ...,\n",
       "         [0.74117647, 0.75294118, 0.80784314],\n",
       "         [0.7372549 , 0.7372549 , 0.78431373],\n",
       "         [0.7254902 , 0.7254902 , 0.77254902]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.74901961, 0.86666667, 0.94117647],\n",
       "         [0.74509804, 0.8627451 , 0.9372549 ],\n",
       "         [0.7372549 , 0.85490196, 0.92941176],\n",
       "         ...,\n",
       "         [0.56470588, 0.68235294, 0.7254902 ],\n",
       "         [0.56470588, 0.68235294, 0.7254902 ],\n",
       "         [0.56862745, 0.68627451, 0.72941176]],\n",
       "\n",
       "        [[0.7254902 , 0.84313725, 0.91764706],\n",
       "         [0.72156863, 0.83921569, 0.91372549],\n",
       "         [0.71372549, 0.83137255, 0.90588235],\n",
       "         ...,\n",
       "         [0.56862745, 0.68627451, 0.72941176],\n",
       "         [0.57254902, 0.69019608, 0.73333333],\n",
       "         [0.57254902, 0.69019608, 0.73333333]],\n",
       "\n",
       "        [[0.70980392, 0.82745098, 0.90196078],\n",
       "         [0.70588235, 0.82352941, 0.89803922],\n",
       "         [0.69803922, 0.81568627, 0.89019608],\n",
       "         ...,\n",
       "         [0.58039216, 0.69803922, 0.74117647],\n",
       "         [0.58431373, 0.70196078, 0.74509804],\n",
       "         [0.58431373, 0.70196078, 0.74509804]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.45098039, 0.22745098, 0.12941176],\n",
       "         [0.44313725, 0.22352941, 0.1254902 ],\n",
       "         [0.45882353, 0.23921569, 0.14117647],\n",
       "         ...,\n",
       "         [0.36078431, 0.35686275, 0.36470588],\n",
       "         [0.38039216, 0.37647059, 0.39215686],\n",
       "         [0.41568627, 0.41176471, 0.42745098]],\n",
       "\n",
       "        [[0.44313725, 0.21960784, 0.12156863],\n",
       "         [0.43921569, 0.21960784, 0.12156863],\n",
       "         [0.45490196, 0.23529412, 0.1372549 ],\n",
       "         ...,\n",
       "         [0.31372549, 0.30980392, 0.3254902 ],\n",
       "         [0.32156863, 0.31372549, 0.3372549 ],\n",
       "         [0.36470588, 0.35686275, 0.38039216]],\n",
       "\n",
       "        [[0.43529412, 0.21176471, 0.11372549],\n",
       "         [0.43137255, 0.21176471, 0.11372549],\n",
       "         [0.44705882, 0.22745098, 0.12941176],\n",
       "         ...,\n",
       "         [0.33333333, 0.32941176, 0.34509804],\n",
       "         [0.39607843, 0.38823529, 0.41176471],\n",
       "         [0.49411765, 0.48627451, 0.50980392]]],\n",
       "\n",
       "\n",
       "       [[[0.95686275, 0.96470588, 0.99607843],\n",
       "         [0.95686275, 0.96470588, 0.99607843],\n",
       "         [0.97254902, 0.98039216, 1.        ],\n",
       "         ...,\n",
       "         [0.37647059, 0.45098039, 0.58823529],\n",
       "         [0.43137255, 0.50588235, 0.64313725],\n",
       "         [0.46666667, 0.54117647, 0.67843137]],\n",
       "\n",
       "        [[0.97254902, 0.98823529, 1.        ],\n",
       "         [0.95294118, 0.96862745, 1.        ],\n",
       "         [0.93333333, 0.94901961, 0.99215686],\n",
       "         ...,\n",
       "         [0.38039216, 0.45490196, 0.59215686],\n",
       "         [0.42352941, 0.49803922, 0.63529412],\n",
       "         [0.45490196, 0.52941176, 0.66666667]],\n",
       "\n",
       "        [[0.5254902 , 0.55686275, 0.62352941],\n",
       "         [0.50196078, 0.53333333, 0.6       ],\n",
       "         [0.4745098 , 0.51372549, 0.58431373],\n",
       "         ...,\n",
       "         [0.39215686, 0.47058824, 0.60784314],\n",
       "         [0.42352941, 0.50196078, 0.63921569],\n",
       "         [0.43921569, 0.51764706, 0.65490196]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.60784314, 0.73333333, 0.8745098 ],\n",
       "         [0.60392157, 0.72941176, 0.87058824],\n",
       "         [0.57254902, 0.70588235, 0.84705882],\n",
       "         ...,\n",
       "         [0.01568627, 0.        , 0.10196078],\n",
       "         [0.01568627, 0.        , 0.10196078],\n",
       "         [0.01568627, 0.        , 0.10196078]],\n",
       "\n",
       "        [[0.55686275, 0.68235294, 0.82352941],\n",
       "         [0.58823529, 0.71372549, 0.85490196],\n",
       "         [0.60784314, 0.74117647, 0.88235294],\n",
       "         ...,\n",
       "         [0.01960784, 0.        , 0.11372549],\n",
       "         [0.01960784, 0.        , 0.11764706],\n",
       "         [0.01960784, 0.        , 0.11764706]],\n",
       "\n",
       "        [[0.50588235, 0.63137255, 0.77254902],\n",
       "         [0.55294118, 0.67843137, 0.81960784],\n",
       "         [0.6       , 0.73333333, 0.8745098 ],\n",
       "         ...,\n",
       "         [0.01960784, 0.        , 0.11764706],\n",
       "         [0.01960784, 0.        , 0.12156863],\n",
       "         [0.01960784, 0.        , 0.12156863]]],\n",
       "\n",
       "\n",
       "       [[[0.45490196, 0.47058824, 0.42352941],\n",
       "         [0.25490196, 0.27058824, 0.22352941],\n",
       "         [0.29019608, 0.30196078, 0.24313725],\n",
       "         ...,\n",
       "         [0.53333333, 0.53333333, 0.53333333],\n",
       "         [0.53333333, 0.53333333, 0.53333333],\n",
       "         [0.53333333, 0.53333333, 0.53333333]],\n",
       "\n",
       "        [[0.47058824, 0.48627451, 0.43921569],\n",
       "         [0.27058824, 0.28627451, 0.23921569],\n",
       "         [0.29019608, 0.30196078, 0.24313725],\n",
       "         ...,\n",
       "         [0.53333333, 0.53333333, 0.53333333],\n",
       "         [0.53333333, 0.53333333, 0.53333333],\n",
       "         [0.53333333, 0.53333333, 0.53333333]],\n",
       "\n",
       "        [[0.49803922, 0.51372549, 0.47058824],\n",
       "         [0.29803922, 0.31372549, 0.26666667],\n",
       "         [0.28627451, 0.29803922, 0.23921569],\n",
       "         ...,\n",
       "         [0.53333333, 0.53333333, 0.53333333],\n",
       "         [0.53333333, 0.53333333, 0.53333333],\n",
       "         [0.53333333, 0.53333333, 0.53333333]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.22352941, 0.28627451, 0.28235294],\n",
       "         [0.25490196, 0.31764706, 0.31372549],\n",
       "         [0.24313725, 0.30588235, 0.30196078],\n",
       "         ...,\n",
       "         [0.37254902, 0.39215686, 0.38823529],\n",
       "         [0.34509804, 0.36470588, 0.36078431],\n",
       "         [0.30980392, 0.32941176, 0.3254902 ]],\n",
       "\n",
       "        [[0.23137255, 0.29411765, 0.29019608],\n",
       "         [0.22352941, 0.28627451, 0.28235294],\n",
       "         [0.21176471, 0.2745098 , 0.27058824],\n",
       "         ...,\n",
       "         [0.36470588, 0.38431373, 0.38039216],\n",
       "         [0.35686275, 0.37647059, 0.37254902],\n",
       "         [0.32941176, 0.34901961, 0.34509804]],\n",
       "\n",
       "        [[0.2745098 , 0.3372549 , 0.33333333],\n",
       "         [0.21960784, 0.28235294, 0.27843137],\n",
       "         [0.19607843, 0.25882353, 0.25490196],\n",
       "         ...,\n",
       "         [0.34117647, 0.36078431, 0.35686275],\n",
       "         [0.34901961, 0.36862745, 0.36470588],\n",
       "         [0.33333333, 0.35294118, 0.34901961]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61d90c1",
   "metadata": {},
   "source": [
    "## Building the Neural Network\n",
    "### Using a Pre trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "695f1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c85ec47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading the mobilenet model from the url\n",
    "MobileNet_model='https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4'\n",
    "\n",
    "pretrained_model=hub.KerasLayer(MobileNet_model,input_shape=(224,224,3),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fab98cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_of_classes=2\n",
    "model=tf.keras.Sequential([pretrained_model,\n",
    "                          tf.keras.layers.Dense(num_of_classes)])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31805ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model with preferred arguments\n",
    "model.compile(optimizer='adam',\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['acc']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f455285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 247s 4s/step - loss: 0.2054 - acc: 0.9175\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 326s 7s/step - loss: 0.0794 - acc: 0.9706\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 397s 8s/step - loss: 0.0587 - acc: 0.9781\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 419s 8s/step - loss: 0.0458 - acc: 0.9850\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 383s 8s/step - loss: 0.0360 - acc: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ccdd9f5780>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_features_train,labels_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6642a0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 125s 9s/step - loss: 0.0665 - acc: 0.9700\n",
      "Test Loss= 0.06651473045349121\n",
      "Test Accuracy= 0.9700000286102295\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test data\n",
    "score, acc = model.evaluate(scaled_features_test,labels_test)\n",
    "print('Test Loss=',score)\n",
    "print('Test Accuracy=',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d21cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With an accuracy of 97% , Basically we can say that the model can identify 97 out of 100 pictures correctly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb3399b",
   "metadata": {},
   "source": [
    "### Defining a Predictor Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ce8ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cat_Or_Dog(image_path):\n",
    "    input_image=cv2.imread(image_path)\n",
    "    cv2.imshow(\"test\",input_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    input_image_resize=cv2.resize(input_image,(224,224))\n",
    "    input_image_scaled=input_image_resize/255\n",
    "    image_reshaped = input_image_scaled.reshape(1,224,224,3) # 1 indicates that we are maling predictions for 1 image\n",
    "    prediction=model.predict(image_reshaped)\n",
    "    print(prediction)\n",
    "    pred_label = np.argmax(prediction)\n",
    "    print(pred_label)\n",
    "    if pred_label==0:\n",
    "        print(\"Its a Dog.. Woof!\")\n",
    "    else:\n",
    "        print(\"Meowww..Its a Cat\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd8a799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "[[-5.0976167  5.704837 ]]\n",
      "1\n",
      "Meowww..Its a Cat\n"
     ]
    }
   ],
   "source": [
    "Cat_Or_Dog('cat_test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb5d42de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 263ms/step\n",
      "[[ 3.8217309 -2.2876353]]\n",
      "0\n",
      "Its a Dog.. Woof!\n"
     ]
    }
   ],
   "source": [
    "Cat_Or_Dog('dog_test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b09bcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load_options.LoadOptions at 0x1ccfc490800>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.saved_model.LoadOptions(\n",
    "    allow_partial_checkpoint=False,\n",
    "    experimental_io_device='/job:localhost',\n",
    "    experimental_skip_checkpoint=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d93d25",
   "metadata": {},
   "source": [
    "### Saving and Loading my Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd671c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2636e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=keras.models.load_model('my_model.h5',custom_objects={'KerasLayer':hub.KerasLayer})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69789449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77979bfe",
   "metadata": {},
   "source": [
    "### Building a Streamlit UI for the WebApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024aa517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
